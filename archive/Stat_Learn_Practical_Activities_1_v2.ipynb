{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot\n",
    "import sklearn.linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import pyreadstat\n",
    "import datetime\n",
    "import FG_Methods\n",
    "import tabulate\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 38718 entries, 0 to 38717\n",
      "Columns: 479 entries, studyno1 to w87\n",
      "dtypes: float64(284), int16(5), int32(3), int8(184), object(3)\n",
      "memory usage: 92.7+ MB\n",
      "['AL', 'AT', 'BA', 'BE', 'BG', 'CH', 'CY', 'CY-TCC', 'CZ', 'DE-E', 'DE-W', 'DK', 'EE', 'ES', 'FI', 'FR', 'GB', 'GR', 'HR', 'HU', 'IE', 'IS', 'IT', 'LT', 'LU', 'LV', 'ME', 'MK', 'MT', 'NL', 'NO', 'PL', 'PT', 'RO', 'RS', 'RS-KM', 'SE', 'SI', 'SK', 'TR']\n"
     ]
    }
   ],
   "source": [
    "# Initialise Values\n",
    "\n",
    "df_path = \"C:\\\\Users\\\\fabio\\\\OneDrive\\\\Documents\\\\Studies\\\\Social_Research\\\\data\\\\ZA7780_v1-0-0.dta\"\n",
    "df = pd.read_stata(df_path, convert_categoricals=False)\n",
    "df.info()\n",
    "\n",
    "unique_country_codes = set(df[\"isocntry\"].values)\n",
    "unique_country_codes = sorted(unique_country_codes)\n",
    "print(unique_country_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'project_folder = \"C:\\\\Users\\\\fabio\\\\OneDrive\\\\Documents\\\\Studies\\\\Social_Research\\\\\"\\n\\ndf_column_headers = \"\"\\nfor i in df.columns:\\n    if i == df.columns[0]:\\n        df_column_headers = i\\n    else:\\n        df_column_headers = df_column_headers + \", \" + i\\n\\nnp.savetxt(project_folder + \\'social_research_dataframe.csv\\',  np.asarray(df), header=df_column_headers, delimiter=\\',\\', fmt=\\'%s\\')'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Output Dataframe as csv\n",
    "\n",
    "\"\"\"project_folder = \"C:\\\\Users\\\\fabio\\\\OneDrive\\\\Documents\\\\Studies\\\\Social_Research\\\\\"\n",
    "\n",
    "df_column_headers = \"\"\n",
    "for i in df.columns:\n",
    "    if i == df.columns[0]:\n",
    "        df_column_headers = i\n",
    "    else:\n",
    "        df_column_headers = df_column_headers + \", \" + i\n",
    "\n",
    "np.savetxt(project_folder + 'social_research_dataframe.csv',  np.asarray(df), header=df_column_headers, delimiter=',', fmt='%s')\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">qa1a</th>\n",
       "      <th colspan=\"2\" halign=\"left\">qa2a</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Italy</th>\n",
       "      <td>3.14</td>\n",
       "      <td>0.84</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Latvia</th>\n",
       "      <td>2.67</td>\n",
       "      <td>0.73</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Romania</th>\n",
       "      <td>2.87</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2.24</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UK</th>\n",
       "      <td>2.62</td>\n",
       "      <td>0.83</td>\n",
       "      <td>1.88</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         qa1a        qa2a      \n",
       "         mean   std  mean   std\n",
       "country                        \n",
       "Italy    3.14  0.84  2.17  0.90\n",
       "Latvia   2.67  0.73  2.17  0.80\n",
       "Romania  2.87  0.99  2.24  0.87\n",
       "UK       2.62  0.83  1.88  0.88"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Note this is currently unweighted\"\"\"\n",
    "\"\"\"This is the old version of the data, since I decide to go for a dictionary approach\"\"\"\n",
    "\n",
    "def fg_counter(counter_value, total_iterations_qty, start, number_of_updates_required_for_total_run = 10, update_counter = False):\n",
    "    if float(counter_value) % int(total_iterations_qty / number_of_updates_required_for_total_run) == 0:\n",
    "        print(\"-----\")\n",
    "        print(datetime.now())\n",
    "        PC = float(float(counter_value) / total_iterations_qty)\n",
    "        print(str(counter_value) + \" / \" + str(total_iterations_qty))\n",
    "        print(PC)\n",
    "        print(\"end estimate @: \" + str((datetime.now() - start) * (total_iterations_qty / counter_value) + datetime.now()))\n",
    "        if update_counter == True:\n",
    "            return PC    \n",
    "\n",
    "def transfer_columns(new_df, original_df, target_string, target_string_at_start=True, data_columns_exact_match=False):\n",
    "    #this method scans every column header of original_df and if target_string is contained within a header, at column is added to new df.\n",
    "    #this allows me to iterativelly add groups of columns from the original datarame to the reduced datafrom for the analysis\n",
    "    #target string must be entered as a string\n",
    "    columns_original = original_df.columns\n",
    "    columns_new = new_df.columns\n",
    "    if type(target_string) is str:\n",
    "        target_string = [target_string]\n",
    "    \n",
    "    for string_ in target_string:\n",
    "        for col in columns_original:\n",
    "            if col.find(string_) >= 0 and not col in new_df and target_string_at_start==False: #FG_Note: test this additional boolean\n",
    "                new_df = pd.concat([new_df, original_df[col]], axis=1)\n",
    "            if col.find(string_) == 0 and not col in new_df and target_string_at_start==True:\n",
    "                new_df = pd.concat([new_df, original_df[col]], axis=1)\n",
    "        \n",
    "    return new_df\n",
    "\n",
    "def return_stats_on_group(original_df, group_column, group_identifiers, data_group, data_columns_exact_match=False):\n",
    "\n",
    "    group_flag = []\n",
    "    group_flag = np.array(original_df[group_column] == group_identifiers[0])\n",
    "\n",
    "    for i in range(1, len(group_identifiers)):\n",
    "        group_flag_ = np.array(original_df[group_column] == group_identifiers[i])\n",
    "        group_flag = group_flag | group_flag_\n",
    "    results_df = original_df[group_flag]\n",
    "    \n",
    "    results_df = results_df.drop(group_column, axis=1) \n",
    "    columns = results_df.columns\n",
    "    for col in columns:\n",
    "            if col.find(data_group[0]) == -1:\n",
    "                results_df = results_df.drop(col, axis=1)\n",
    "    \n",
    "\n",
    "\n",
    "    #print(type(float(\"{:.2f}\".format(results_df.values.mean()))))\n",
    "\n",
    "    return float(\"{:.2f}\".format(results_df.values.mean())), float(\"{:.2f}\".format(results_df.values.std()))\n",
    "    #return results_df.values.mean(), results_df.values.std()\n",
    "\n",
    "def run_study(unit_request_list, unit_column, unit_type, data_request_list):\n",
    "    df_results = pd.DataFrame()\n",
    "    df_reduced = pd.DataFrame()\n",
    "    df_reduced = transfer_columns(df_reduced, df, [unit_column], target_string_at_start=True, data_columns_exact_match=False)    \n",
    "    for data_request in data_request_list:\n",
    "        df_reduced = transfer_columns(df_reduced, df, data_request[\"data_group\"], target_string_at_start=True, data_columns_exact_match=False)    \n",
    "\n",
    "    for unit_request in unit_request_list:\n",
    "        result_series_2 = pd.Series()\n",
    "        for data_request in data_request_list:\n",
    "            output_mean, output_std = return_stats_on_group(df_reduced, unit_column, unit_request[\"unit_group\"], data_request[\"data_group\"], data_columns_exact_match=False)\n",
    "\n",
    "            #enter data to series\n",
    "            result_dict = {(data_request[\"data_group_name\"], \"mean\"): output_mean, (data_request[\"data_group_name\"], \"std\"): output_std}\n",
    "            result_series = pd.Series(result_dict, name=unit_request[\"unit_name\"])\n",
    "            df_results = df_results.append(result_series)\n",
    "\n",
    "    df_results[unit_type] = df_results.index\n",
    "    df_results = df_results.groupby(unit_type).mean()\n",
    "    return df_results\n",
    "\n",
    "\n",
    "#With the key being: Country, Value Name, Value\n",
    "\n",
    "#create data request\n",
    "unit_request_list = [{\"unit_group\" : [\"GB\"], \"unit_name\": \"UK\"},\n",
    "                     {\"unit_group\" : [\"IT\"], \"unit_name\": \"Italy\"},\n",
    "                     {\"unit_group\" : [\"LV\"], \"unit_name\": \"Latvia\"},\n",
    "                     {\"unit_group\" : [\"RO\"], \"unit_name\": \"Romania\"}]\n",
    "unit_column = \"isocntry\"\n",
    "unit_type = \"country\"\n",
    "data_request_list = [{\"data_group\": [\"qa1a_\"], \"data_group_name\": \"qa1a\"},\n",
    "                     {\"data_group\": [\"qa2a_\"], \"data_group_name\": \"qa2a\"}]\n",
    "\n",
    "df_results = run_study(unit_request_list, unit_column, unit_type, data_request_list)\n",
    "df_results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">qa1a</th>\n",
       "      <th colspan=\"2\" halign=\"left\">qa2a</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>2.25</td>\n",
       "      <td>0.93</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Italy</th>\n",
       "      <td>2.65</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.65</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         qa1a        qa2a      \n",
       "         mean   std  mean   std\n",
       "country                        \n",
       "GB       2.25  0.93  2.25  0.93\n",
       "Italy    2.65  1.00  2.65  1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Note this is currently unweighted\"\"\"\n",
    "\"\"\"This is the old version of the data, since I decide to go for a dictionary approach\"\"\"\n",
    "\n",
    "def fg_counter(counter_value, total_iterations_qty, start, number_of_updates_required_for_total_run = 10, update_counter = False):\n",
    "    if float(counter_value) % int(total_iterations_qty / number_of_updates_required_for_total_run) == 0:\n",
    "        print(\"-----\")\n",
    "        print(datetime.now())\n",
    "        PC = float(float(counter_value) / total_iterations_qty)\n",
    "        print(str(counter_value) + \" / \" + str(total_iterations_qty))\n",
    "        print(PC)\n",
    "        print(\"end estimate @: \" + str((datetime.now() - start) * (total_iterations_qty / counter_value) + datetime.now()))\n",
    "        if update_counter == True:\n",
    "            return PC    \n",
    "\n",
    "def transfer_columns(new_df, original_df, target_string, target_string_at_start=True, data_columns_exact_match=False):\n",
    "    #this method scans every column header of original_df and if target_string is contained within a header, at column is added to new df.\n",
    "    #this allows me to iterativelly add groups of columns from the original datarame to the reduced datafrom for the analysis\n",
    "    #target string must be entered as a string\n",
    "    columns_original = original_df.columns\n",
    "    columns_new = new_df.columns\n",
    "    if type(target_string) is str:\n",
    "        target_string = [target_string]\n",
    "    \n",
    "    for string_ in target_string:\n",
    "        for col in columns_original:\n",
    "            if col.find(string_) >= 0 and not col in new_df and target_string_at_start==False: #FG_Note: test this additional boolean\n",
    "                new_df = pd.concat([new_df, original_df[col]], axis=1)\n",
    "            if col.find(string_) == 0 and not col in new_df and target_string_at_start==True:\n",
    "                new_df = pd.concat([new_df, original_df[col]], axis=1)\n",
    "        \n",
    "    return new_df\n",
    "\n",
    "def return_stats_on_group(original_df, group_column, group_identifiers, data_group, data_columns_exact_match=False):\n",
    "\n",
    "    group_flag = []\n",
    "    group_flag = np.array(original_df[group_column] == group_identifiers[0])\n",
    "\n",
    "    for i in range(1, len(group_identifiers)):\n",
    "        group_flag_ = np.array(original_df[group_column] == i)\n",
    "        group_flag = group_flag or group_flag_\n",
    "    results_df = original_df[group_flag]\n",
    "    results_df = results_df.drop(group_column, axis=1) \n",
    "\n",
    "    #print(type(float(\"{:.2f}\".format(results_df.values.mean()))))\n",
    "\n",
    "    return float(\"{:.2f}\".format(results_df.values.mean())), float(\"{:.2f}\".format(results_df.values.std()))\n",
    "\n",
    "#create data request\n",
    "unit_request_list = [{\"unit_group\" : [\"GB\"], \"unit_name\": \"GB\"},\n",
    "                     {\"unit_group\" : [\"IT\"], \"unit_name\": \"Italy\"}]\n",
    "unit_column = \"isocntry\"\n",
    "unit_type = \"country\"\n",
    "data_request_list = [{\"data_group\": [\"qa1a_\"], \"data_group_name\": \"qa1a\"},\n",
    "                     {\"data_group\": [\"qa2a_\"], \"data_group_name\": \"qa2a\"}]\n",
    "\n",
    "df_results = pd.DataFrame()\n",
    "df_reduced = pd.DataFrame()\n",
    "df_reduced = transfer_columns(df_reduced, df, [unit_column], target_string_at_start=True, data_columns_exact_match=False)    \n",
    "for data_request in data_request_list:\n",
    "    df_reduced = transfer_columns(df_reduced, df, data_request[\"data_group\"], target_string_at_start=True, data_columns_exact_match=False)    \n",
    "\n",
    "for unit_request in unit_request_list:\n",
    "    result_series_2 = pd.Series()\n",
    "    for data_request in data_request_list:\n",
    "        output_mean, output_std = return_stats_on_group(df_reduced, unit_column, unit_request[\"unit_group\"], data_request[\"data_group\"], data_columns_exact_match=False)\n",
    "\n",
    "        #enter data to series\n",
    "        result_dict = {(data_request[\"data_group_name\"], \"mean\"): output_mean, (data_request[\"data_group_name\"], \"std\"): output_std}\n",
    "        result_series = pd.Series(result_dict, name=unit_request[\"unit_name\"])\n",
    "        df_results = df_results.append(result_series)\n",
    "\n",
    "df_results[unit_type] = df_results.index\n",
    "df_results = df_results.groupby(unit_type).mean()\n",
    "df_results\n",
    "\n",
    "#With the key being: Country, Value Name, Value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ES', 'IE', 'LT', 'NO', 'IS', 'CZ', 'CY-TCC', 'AT', 'GB', 'FR', 'BA', 'RO', 'AL', 'NL', 'ME', 'CH', 'DE-W', 'MT', 'RS', 'BE', 'LU', 'DE-E', 'HU', 'IT', 'CY', 'SK', 'BG', 'PT', 'LV', 'PL', 'MK', 'DK', 'RS-KM', 'SE', 'SI', 'EE', 'TR', 'GR', 'HR', 'FI'}\n"
     ]
    }
   ],
   "source": [
    "f = df[\"isocntry\"].values\n",
    "g = set(f)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_results.loc[[\"qa1a\", \"mean\"]]\n",
    "#df_results.loc[\"GB\"][\"qa1a\"][\"mean\"]\n",
    "\n",
    "(df_results.index == \"GB\").any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_columns = [\"qa1a_1\", \"qa1a_2\", \"qa1a_3\"]\n",
    "df_test = df.loc[df[\"isocntry\"] == \"GB\"]\n",
    "\n",
    "test = df_test[test_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is for experimenting with mutli-dimensional python dictionaries\n",
    "\n",
    "test_dic = {\n",
    "('A', 'a', \"mean\"): [1, 2, 3, 4, 5],\n",
    "('A', 'a', \"std\"): [1, 2, 3, 4, 5],\n",
    "('A', 'b', \"mean\"): [6, 7, 8, 9, 1],\n",
    "('A', 'b', \"std\"): [6, 7, 8, 9, 1],\n",
    "('B', 'a', \"mean\"): [2, 3, 4, 5, 6],\n",
    "('B', 'a', \"std\"): [2, 3, 4, 5, 6],\n",
    "('B', 'b', \"mean\"): [7, 8, 9, 1, 2],\n",
    "('B', 'b', \"std\"): [7, 8, 9, 1, 2] }\n",
    "\n",
    "\n",
    "\n",
    "test_dic_insert = {\n",
    "('a', \"mean\"): [1, 2, 3, 4, 5],\n",
    "('a', \"std\"): [1, 2, 3, 4, 5],\n",
    "('b', \"mean\"): [6, 7, 8, 9, 1],\n",
    "('b', \"std\"): [6, 7, 8, 9, 1],\n",
    "}\n",
    "\n",
    "\n",
    "#def update_key(dict):\n",
    "#    for entry in dict:\n",
    "\n",
    "dict_1 = {(\"group_1\", \"mean\"): 1, (\"group_1\", \"std\"): 2,\n",
    "          (\"group_2\", \"mean\"): 2, (\"group_2\", \"std\"): 0.5}\n",
    "test_series_1 = pd.Series(dict_1, name=\"GB\")\n",
    "\n",
    "dict_2 = {(\"group_1\", \"mean\"): 3, (\"group_1\", \"std\"): 3,\n",
    "          (\"group_2\", \"mean\"): 5, (\"group_2\", \"std\"): 8}\n",
    "test_series_2 = pd.Series(dict_2, name=\"IT\")\n",
    "\n",
    "pd.DataFrame([test_series_1, test_series_2])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d686fb4bba1cd81d322bac49812b464465e293b78591a47e52bedfb124e592be"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
