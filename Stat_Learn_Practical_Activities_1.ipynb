{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot\n",
    "import sklearn.linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import pyreadstat\n",
    "import datetime\n",
    "import FG_Methods\n",
    "import tabulate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 38718 entries, 0 to 38717\n",
      "Columns: 479 entries, studyno1 to w87\n",
      "dtypes: float64(284), int16(5), int32(3), int8(184), object(3)\n",
      "memory usage: 92.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_path = \"C:\\\\Users\\\\fabio\\\\OneDrive\\\\Documents\\\\Studies\\\\Social_Research\\\\data\\\\ZA7780_v1-0-0.dta\"\n",
    "df = pd.read_stata(df_path, convert_categoricals=False)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'project_folder = \"C:\\\\Users\\\\fabio\\\\OneDrive\\\\Documents\\\\Studies\\\\Social_Research\\\\\"\\n\\ndf_column_headers = \"\"\\nfor i in df.columns:\\n    if i == df.columns[0]:\\n        df_column_headers = i\\n    else:\\n        df_column_headers = df_column_headers + \", \" + i\\n\\nnp.savetxt(project_folder + \\'social_research_dataframe.csv\\',  np.asarray(df), header=df_column_headers, delimiter=\\',\\', fmt=\\'%s\\')'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Output Dataframe as csv\n",
    "\n",
    "\"\"\"project_folder = \"C:\\\\Users\\\\fabio\\\\OneDrive\\\\Documents\\\\Studies\\\\Social_Research\\\\\"\n",
    "\n",
    "df_column_headers = \"\"\n",
    "for i in df.columns:\n",
    "    if i == df.columns[0]:\n",
    "        df_column_headers = i\n",
    "    else:\n",
    "        df_column_headers = df_column_headers + \", \" + i\n",
    "\n",
    "np.savetxt(project_folder + 'social_research_dataframe.csv',  np.asarray(df), header=df_column_headers, delimiter=',', fmt='%s')\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_3708\\3202534445.py:63: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  result_series_2 = pd.Series()\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_3708\\3202534445.py:70: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_series_2 = result_series_2.append(result_series)\n",
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_3708\\3202534445.py:70: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_series_2 = result_series_2.append(result_series)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Note this is currently unweighted\"\"\"\n",
    "\"\"\"This is the old version of the data, since I decide to go for a dictionary approach\"\"\"\n",
    "\n",
    "def fg_counter(counter_value, total_iterations_qty, start, number_of_updates_required_for_total_run = 10, update_counter = False):\n",
    "    if float(counter_value) % int(total_iterations_qty / number_of_updates_required_for_total_run) == 0:\n",
    "        print(\"-----\")\n",
    "        print(datetime.now())\n",
    "        PC = float(float(counter_value) / total_iterations_qty)\n",
    "        print(str(counter_value) + \" / \" + str(total_iterations_qty))\n",
    "        print(PC)\n",
    "        print(\"end estimate @: \" + str((datetime.now() - start) * (total_iterations_qty / counter_value) + datetime.now()))\n",
    "        if update_counter == True:\n",
    "            return PC    \n",
    "\n",
    "def transfer_columns(new_df, original_df, target_string, target_string_at_start=True, data_columns_exact_match=False):\n",
    "    #this method scans every column header of original_df and if target_string is contained within a header, at column is added to new df.\n",
    "    #this allows me to iterativelly add groups of columns from the original datarame to the reduced datafrom for the analysis\n",
    "    #target string must be entered as a string\n",
    "    columns_original = original_df.columns\n",
    "    columns_new = new_df.columns\n",
    "    if type(target_string) is str:\n",
    "        target_string = [target_string]\n",
    "    \n",
    "    for string_ in target_string:\n",
    "        for col in columns_original:\n",
    "            if col.find(string_) >= 0 and not col in new_df and target_string_at_start==False: #FG_Note: test this additional boolean\n",
    "                new_df = pd.concat([new_df, original_df[col]], axis=1)\n",
    "            if col.find(string_) == 0 and not col in new_df and target_string_at_start==True:\n",
    "                new_df = pd.concat([new_df, original_df[col]], axis=1)\n",
    "        \n",
    "    return new_df\n",
    "\n",
    "def return_stats_on_group(original_df, group_column, group_identifiers, data_group, data_columns_exact_match=False):\n",
    "\n",
    "    group_flag = []\n",
    "    group_flag = np.array(original_df[group_column] == group_identifiers[0])\n",
    "\n",
    "    for i in range(1, len(group_identifiers)):\n",
    "        group_flag_ = np.array(original_df[group_column] == i)\n",
    "        group_flag = group_flag or group_flag_\n",
    "    results_df = original_df[group_flag]\n",
    "    results_df = results_df.drop(group_column, axis=1) \n",
    "\n",
    "    #print(type(float(\"{:.2f}\".format(results_df.values.mean()))))\n",
    "\n",
    "    return float(\"{:.2f}\".format(results_df.values.mean())), float(\"{:.2f}\".format(results_df.values.std()))\n",
    "\n",
    "#create data request\n",
    "unit_request_list = [{\"unit_group\" : [\"GB\"], \"unit_name\": \"GB\"},\n",
    "                     {\"unit_group\" : [\"IT\"], \"unit_name\": \"Italy\"}]\n",
    "unit_column = \"isocntry\"\n",
    "\n",
    "data_request_list = [{\"data_group\": [\"qa1a_\"], \"data_group_name\": \"qa1a\"},\n",
    "                     {\"data_group\": [\"qa2a_\"], \"data_group_name\": \"qa2a\"}]\n",
    "\n",
    "df_results = pd.DataFrame()\n",
    "df_reduced = pd.DataFrame()\n",
    "df_reduced = transfer_columns(df_reduced, df, [unit_column], target_string_at_start=True, data_columns_exact_match=False)    \n",
    "for data_request in data_request_list:\n",
    "    df_reduced = transfer_columns(df_reduced, df, data_request[\"data_group\"], target_string_at_start=True, data_columns_exact_match=False)    \n",
    "\n",
    "for unit_request in unit_request_list:\n",
    "    result_series_2 = pd.Series()\n",
    "    for data_request in data_request_list:\n",
    "        output_mean, output_std = return_stats_on_group(df_reduced, unit_column, unit_request[\"unit_group\"], data_request[\"data_group\"], data_columns_exact_match=False)\n",
    "\n",
    "        #enter data to series\n",
    "        result_dict = {(data_request[\"data_group_name\"], \"mean\"): output_mean, (data_request[\"data_group_name\"], \"std\"): output_std}\n",
    "        result_series = pd.Series(result_dict, name=unit_request[\"unit_name\"])\n",
    "        result_series_2 = result_series_2.append(result_series)\n",
    "        \"\"\"if not (df_results.index == \"GB\").any():\n",
    "            df_results = df_results.append(result_series)\n",
    "        elif not str(df_results.columns).find(data_request[\"data_group_name\"]) >= 0:\n",
    "            #str(df_results.index).find(data_request[\"data_group_name\"]) >= 0\n",
    "            df_results = pd.merge(df_results, pd.DataFrame(result_series), left_index=True, right_index=True)\n",
    " \n",
    "            print(\"Hello\")\n",
    "        else:\n",
    "            print(\"Hello\")\"\"\"\n",
    "        #df_results.loc[\"qa1a\"] = df_results.append(result_series)\n",
    "        #df_results.loc[unit_request[\"unit_name\"]][data_request[\"data_group_name\"]][\"mean\"] = output_mean\n",
    "        #df_results.loc[unit_request[\"unit_name\"]][data_request[\"data_group_name\"]][\"std\"] = output_std\n",
    "    \n",
    "    result_series_2.name = unit_request[\"unit_name\"]\n",
    "    df_results = df_results.append(result_series_2, index=unit_request[\"unit_name\"])\n",
    "\n",
    "df_results\n",
    "\n",
    "#I need to reform the data as a multi-index dictionary.\n",
    "#With the key being: Country, Value Name, Value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'GB'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\fabio\\OneDrive\\Documents\\Studies\\Social_Research\\Statistical-Learning_Exercise-1_Trust-within-the-EU\\Stat_Learn_Practical_Activities_1.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/fabio/OneDrive/Documents/Studies/Social_Research/Statistical-Learning_Exercise-1_Trust-within-the-EU/Stat_Learn_Practical_Activities_1.ipynb#ch0000006?line=0'>1</a>\u001b[0m df_results_2 \u001b[39m=\u001b[39m df_results\u001b[39m.\u001b[39;49mgroupby([\u001b[39m\"\u001b[39;49m\u001b[39mGB\u001b[39;49m\u001b[39m\"\u001b[39;49m,\u001b[39m\"\u001b[39;49m\u001b[39mItaly\u001b[39;49m\u001b[39m\"\u001b[39;49m])\u001b[39m.\u001b[39mmean()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:7706\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/frame.py?line=7700'>7701</a>\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m   <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/frame.py?line=7702'>7703</a>\u001b[0m \u001b[39m# https://github.com/python/mypy/issues/7642\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/frame.py?line=7703'>7704</a>\u001b[0m \u001b[39m# error: Argument \"squeeze\" to \"DataFrameGroupBy\" has incompatible type\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/frame.py?line=7704'>7705</a>\u001b[0m \u001b[39m# \"Union[bool, NoDefault]\"; expected \"bool\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/frame.py?line=7705'>7706</a>\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameGroupBy(\n\u001b[0;32m   <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/frame.py?line=7706'>7707</a>\u001b[0m     obj\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/frame.py?line=7707'>7708</a>\u001b[0m     keys\u001b[39m=\u001b[39;49mby,\n\u001b[0;32m   <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/frame.py?line=7708'>7709</a>\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m   <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/frame.py?line=7709'>7710</a>\u001b[0m     level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m   <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/frame.py?line=7710'>7711</a>\u001b[0m     as_index\u001b[39m=\u001b[39;49mas_index,\n\u001b[0;32m   <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/frame.py?line=7711'>7712</a>\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m   <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/frame.py?line=7712'>7713</a>\u001b[0m     group_keys\u001b[39m=\u001b[39;49mgroup_keys,\n\u001b[0;32m   <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/frame.py?line=7713'>7714</a>\u001b[0m     squeeze\u001b[39m=\u001b[39;49msqueeze,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/frame.py?line=7714'>7715</a>\u001b[0m     observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m   <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/frame.py?line=7715'>7716</a>\u001b[0m     dropna\u001b[39m=\u001b[39;49mdropna,\n\u001b[0;32m   <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/frame.py?line=7716'>7717</a>\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py:882\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/groupby/groupby.py?line=878'>879</a>\u001b[0m \u001b[39mif\u001b[39;00m grouper \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/groupby/groupby.py?line=879'>880</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgroupby\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mgrouper\u001b[39;00m \u001b[39mimport\u001b[39;00m get_grouper\n\u001b[1;32m--> <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/groupby/groupby.py?line=881'>882</a>\u001b[0m     grouper, exclusions, obj \u001b[39m=\u001b[39m get_grouper(\n\u001b[0;32m    <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/groupby/groupby.py?line=882'>883</a>\u001b[0m         obj,\n\u001b[0;32m    <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/groupby/groupby.py?line=883'>884</a>\u001b[0m         keys,\n\u001b[0;32m    <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/groupby/groupby.py?line=884'>885</a>\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/groupby/groupby.py?line=885'>886</a>\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[0;32m    <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/groupby/groupby.py?line=886'>887</a>\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[0;32m    <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/groupby/groupby.py?line=887'>888</a>\u001b[0m         observed\u001b[39m=\u001b[39;49mobserved,\n\u001b[0;32m    <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/groupby/groupby.py?line=888'>889</a>\u001b[0m         mutated\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmutated,\n\u001b[0;32m    <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/groupby/groupby.py?line=889'>890</a>\u001b[0m         dropna\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropna,\n\u001b[0;32m    <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/groupby/groupby.py?line=890'>891</a>\u001b[0m     )\n\u001b[0;32m    <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/groupby/groupby.py?line=892'>893</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m obj\n\u001b[0;32m    <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/groupby/groupby.py?line=893'>894</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\groupby\\grouper.py:882\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/groupby/grouper.py?line=879'>880</a>\u001b[0m         in_axis, level, gpr \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, gpr, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/groupby/grouper.py?line=880'>881</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/groupby/grouper.py?line=881'>882</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(gpr)\n\u001b[0;32m    <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/groupby/grouper.py?line=882'>883</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(gpr, Grouper) \u001b[39mand\u001b[39;00m gpr\u001b[39m.\u001b[39mkey \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/groupby/grouper.py?line=883'>884</a>\u001b[0m     \u001b[39m# Add key to exclusions\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/fabio/AppData/Local/Programs/Python/Python310/lib/site-packages/pandas/core/groupby/grouper.py?line=884'>885</a>\u001b[0m     exclusions\u001b[39m.\u001b[39madd(gpr\u001b[39m.\u001b[39mkey)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'GB'"
     ]
    }
   ],
   "source": [
    "df_results_2 = df_results.groupby([\"GB\",\"Italy\"]).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_results.loc[[\"qa1a\", \"mean\"]]\n",
    "#df_results.loc[\"GB\"][\"qa1a\"][\"mean\"]\n",
    "\n",
    "(df_results.index == \"GB\").any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_columns = [\"qa1a_1\", \"qa1a_2\", \"qa1a_3\"]\n",
    "df_test = df.loc[df[\"isocntry\"] == \"GB\"]\n",
    "\n",
    "test = df_test[test_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is for experimenting with mutli-dimensional python dictionaries\n",
    "\n",
    "test_dic = {\n",
    "('A', 'a', \"mean\"): [1, 2, 3, 4, 5],\n",
    "('A', 'a', \"std\"): [1, 2, 3, 4, 5],\n",
    "('A', 'b', \"mean\"): [6, 7, 8, 9, 1],\n",
    "('A', 'b', \"std\"): [6, 7, 8, 9, 1],\n",
    "('B', 'a', \"mean\"): [2, 3, 4, 5, 6],\n",
    "('B', 'a', \"std\"): [2, 3, 4, 5, 6],\n",
    "('B', 'b', \"mean\"): [7, 8, 9, 1, 2],\n",
    "('B', 'b', \"std\"): [7, 8, 9, 1, 2] }\n",
    "\n",
    "\n",
    "\n",
    "test_dic_insert = {\n",
    "('a', \"mean\"): [1, 2, 3, 4, 5],\n",
    "('a', \"std\"): [1, 2, 3, 4, 5],\n",
    "('b', \"mean\"): [6, 7, 8, 9, 1],\n",
    "('b', \"std\"): [6, 7, 8, 9, 1],\n",
    "}\n",
    "\n",
    "\n",
    "#def update_key(dict):\n",
    "#    for entry in dict:\n",
    "\n",
    "dict_1 = {(\"group_1\", \"mean\"): 1, (\"group_1\", \"std\"): 2,\n",
    "          (\"group_2\", \"mean\"): 2, (\"group_2\", \"std\"): 0.5}\n",
    "test_series_1 = pd.Series(dict_1, name=\"GB\")\n",
    "\n",
    "dict_2 = {(\"group_1\", \"mean\"): 3, (\"group_1\", \"std\"): 3,\n",
    "          (\"group_2\", \"mean\"): 5, (\"group_2\", \"std\"): 8}\n",
    "test_series_2 = pd.Series(dict_2, name=\"IT\")\n",
    "\n",
    "pd.DataFrame([test_series_1, test_series_2])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d686fb4bba1cd81d322bac49812b464465e293b78591a47e52bedfb124e592be"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
