{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot\n",
    "import sklearn.linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import pyreadstat\n",
    "import datetime\n",
    "import FG_Methods_1\n",
    "import tabulate\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 38718 entries, 0 to 38717\n",
      "Columns: 479 entries, studyno1 to w87\n",
      "dtypes: float64(284), int16(5), int32(3), int8(184), object(3)\n",
      "memory usage: 92.7+ MB\n",
      "['AL', 'AT', 'BA', 'BE', 'BG', 'CH', 'CY', 'CY-TCC', 'CZ', 'DE-E', 'DE-W', 'DK', 'EE', 'ES', 'FI', 'FR', 'GB', 'GR', 'HR', 'HU', 'IE', 'IS', 'IT', 'LT', 'LU', 'LV', 'ME', 'MK', 'MT', 'NL', 'NO', 'PL', 'PT', 'RO', 'RS', 'RS-KM', 'SE', 'SI', 'SK', 'TR']\n"
     ]
    }
   ],
   "source": [
    "# Initialise Values\n",
    "\n",
    "df_path = \"C:\\\\Users\\\\fabio\\\\OneDrive\\\\Documents\\\\Studies\\\\Social_Research\\\\data\\\\ZA7780_v1-0-0.dta\"\n",
    "df = pd.read_stata(df_path, convert_categoricals=False)\n",
    "df.info()\n",
    "\n",
    "unique_country_codes = set(df[\"isocntry\"].values)\n",
    "unique_country_codes = sorted(unique_country_codes)\n",
    "print(unique_country_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'project_folder = \"C:\\\\Users\\\\fabio\\\\OneDrive\\\\Documents\\\\Studies\\\\Social_Research\\\\\"\\n\\ndf_column_headers = \"\"\\nfor i in df.columns:\\n    if i == df.columns[0]:\\n        df_column_headers = i\\n    else:\\n        df_column_headers = df_column_headers + \", \" + i\\n\\nnp.savetxt(project_folder + \\'social_research_dataframe.csv\\',  np.asarray(df), header=df_column_headers, delimiter=\\',\\', fmt=\\'%s\\')'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Output Dataframe as csv\n",
    "\n",
    "\"\"\"project_folder = \"C:\\\\Users\\\\fabio\\\\OneDrive\\\\Documents\\\\Studies\\\\Social_Research\\\\\"\n",
    "\n",
    "df_column_headers = \"\"\n",
    "for i in df.columns:\n",
    "    if i == df.columns[0]:\n",
    "        df_column_headers = i\n",
    "    else:\n",
    "        df_column_headers = df_column_headers + \", \" + i\n",
    "\n",
    "np.savetxt(project_folder + 'social_research_dataframe.csv',  np.asarray(df), header=df_column_headers, delimiter=',', fmt='%s')\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-25 17:36:05.100894\n",
      "1298\n"
     ]
    }
   ],
   "source": [
    "def return_stats_on_group(df, column_names, conditions, remap_dict):\n",
    "    df_filtered = df\n",
    "    collected_values, collected_means = [], []\n",
    "    \n",
    "    for col, condition in conditions.items():\n",
    "        df_filtered = df_filtered[df_filtered[col]==condition]\n",
    "    for target_value in column_names:\n",
    "        df_remapped = df_filtered[target_value]\n",
    "        if not remap_dict == None:\n",
    "            FG_counter = 0\n",
    "            total_iterations_qty = len(df_remapped.index)\n",
    "            print(total_iterations_qty)\n",
    "            for i in df_remapped.index[0:100]:\n",
    "                FG_counter += 1\n",
    "                if float(FG_counter) % int(total_iterations_qty / 10) == 0:\n",
    "                    print(str(FG_counter) + \"/\" +  str(total_iterations_qty))\n",
    "                    print(datetime.datetime.now())\n",
    "                df_remapped[i] = remap_dict[df_remapped[i]]\n",
    "            \n",
    "        collected_means  = np.append(collected_means, df_remapped.mean())\n",
    "        collected_values = np.append(collected_values, df_remapped.values.tolist())\n",
    "    \n",
    "    output_mean, output_std = collected_means.mean(), np.array(collected_values).std()\n",
    "    output_mean, output_std = float(\"{:.2f}\".format(output_mean)), float(\"{:.2f}\".format(output_std))\n",
    "    \n",
    "    return output_mean, output_std\n",
    "\n",
    "def run_study(unit_group_request_list, unit_group_column, unit_group_name, data_request_list):\n",
    "    df_results = pd.DataFrame()\n",
    "    \n",
    "    for unit_request in unit_group_request_list:\n",
    "        unit_request_2 = {unit_group_column: v for v in unit_request[\"unit_group\"]}\n",
    "        \n",
    "        for data_request in data_request_list:\n",
    "            remap_dict = data_request[\"remap_dict\"]\n",
    "            output_mean, output_std = return_stats_on_group(df, data_request['data_group'], unit_request_2, remap_dict)\n",
    "            \n",
    "            #enter data to series - FG_note: this likely still clunkly, I'm not sure why I'm using all these dictionaries\n",
    "            result_dict = {(data_request[\"data_group_name\"], \"mean\"): output_mean, (data_request[\"data_group_name\"], \"std\"): output_std}\n",
    "            result_series = pd.Series(result_dict, name=unit_request[\"unit_name\"])\n",
    "            df_results = df_results.append(result_series)\n",
    "    \n",
    "    df_results[unit_group_name] = df_results.index\n",
    "    df_results = df_results.groupby(unit_type).mean()\n",
    "    return df_results\n",
    "\n",
    "remap_1 = {1:2, 2:3, 3:4, 4:5, 5:6}\n",
    "unit_group_request_list = [{\"unit_group\" : [\"GB\"], \"unit_name\": \"GB\"}, \n",
    "                           {\"unit_group\" : [\"IT\"], \"unit_name\": \"Italy\"}]\n",
    "unit_group_column = \"isocntry\"\n",
    "unit_group_name = \"country\"\n",
    "data_request_list = [{\"data_group\": [\"qa1a_1\", \"qa1a_2\", \"qa1a_3\", \"qa1a_4\", \"qa1a_5\", \"qa1a_6\", \"qa1a_7\"], \"data_group_name\": \"qa1a\", \"remap_dict\": remap_1},\n",
    "                     {\"data_group\": [\"qa2a_1\", \"qa2a_2\", \"qa2a_3\", \"qa2a_4\", \"qa2a_5\", \"qa2a_6\", \"qa2a_7\"], \"data_group_name\": \"qa2a\", \"remap_dict\": None}]\n",
    "\n",
    "test_list = [\"a\",\"b\"]\n",
    "test_dict = {\"a\":1, \"b\":2}\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "#return_stats_on_group(df, [\"qa1a_2\"], {\"isocntry\":\"LT\"})\n",
    "df_results = run_study(unit_group_request_list, unit_group_column, unit_group_name, data_request_list)\n",
    "print(df_results)\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df[[\"isocntry\",\"qa1a_2\",\"d8\"]]\n",
    "df_2 = df_1[df_1['isocntry']==\"LT\"]\n",
    "corr_education_econ = df_2[\"qa1a_2\"].corr(df_2[\"d8\"])\n",
    "print(corr_education_econ)\n",
    "\n",
    "\n",
    "plt.scatter(df_2[\"d8\"], df_2[\"qa1a_2\"])\n",
    "df_2.hist(\"qa1a_2\")\n",
    "sns.pairplot(df_2[['qa1a_2', \"d8\"]], palette=\"vlag\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d686fb4bba1cd81d322bac49812b464465e293b78591a47e52bedfb124e592be"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
