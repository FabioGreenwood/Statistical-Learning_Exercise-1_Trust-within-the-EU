{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot\n",
    "import sklearn.linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "import pyreadstat\n",
    "import datetime\n",
    "import FG_Methods\n",
    "import tabulate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 38718 entries, 0 to 38717\n",
      "Columns: 479 entries, studyno1 to w87\n",
      "dtypes: float64(284), int16(5), int32(3), int8(184), object(3)\n",
      "memory usage: 92.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_path = \"C:\\\\Users\\\\fabio\\\\OneDrive\\\\Documents\\\\Studies\\\\Social_Research\\\\data\\\\ZA7780_v1-0-0.dta\"\n",
    "df = pd.read_stata(df_path, convert_categoricals=False)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output Dataframe as csv\n",
    "\n",
    "project_folder = \"C:\\\\Users\\\\fabio\\\\OneDrive\\\\Documents\\\\Studies\\\\Social_Research\\\\\"\n",
    "\n",
    "df_column_headers = \"\"\n",
    "for i in df.columns:\n",
    "    if i == df.columns[0]:\n",
    "        df_column_headers = i\n",
    "    else:\n",
    "        df_column_headers = df_column_headers + \", \" + i\n",
    "\n",
    "np.savetxt(project_folder + 'social_research_dataframe.csv',  np.asarray(df), header=df_column_headers, delimiter=',', fmt='%s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fabio\\AppData\\Local\\Temp\\ipykernel_9148\\3966432523.py:60: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_results = df_results.append(result_series)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">qa1a</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GB</th>\n",
       "      <td>2.62</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    qa1a      \n",
       "    mean   std\n",
       "GB  2.62  0.83"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Note this is currently unweighted\"\"\"\n",
    "\"\"\"This is the old version of the data, since I decide to go for a dictionary approach\"\"\"\n",
    "\n",
    "def fg_counter(counter_value, total_iterations_qty, start, number_of_updates_required_for_total_run = 10, update_counter = False):\n",
    "    if float(counter_value) % int(total_iterations_qty / number_of_updates_required_for_total_run) == 0:\n",
    "        print(\"-----\")\n",
    "        print(datetime.now())\n",
    "        PC = float(float(counter_value) / total_iterations_qty)\n",
    "        print(str(counter_value) + \" / \" + str(total_iterations_qty))\n",
    "        print(PC)\n",
    "        print(\"end estimate @: \" + str((datetime.now() - start) * (total_iterations_qty / counter_value) + datetime.now()))\n",
    "        if update_counter == True:\n",
    "            return PC    \n",
    "\n",
    "def transfer_columns(new_df, original_df, target_string, target_string_at_start=True, data_columns_exact_match=False):\n",
    "    #this method scans every column header of original_df and if target_string is contained within a header, at column is added to new df.\n",
    "    #this allows me to iterativelly add groups of columns from the original datarame to the reduced datafrom for the analysis\n",
    "    #target string must be entered as a string\n",
    "    columns = original_df.columns\n",
    "    if type(target_string) is str:\n",
    "        target_string = [target_string]\n",
    "    \n",
    "    for string_ in target_string:\n",
    "        for col in columns:\n",
    "            if col.find(string_) >= 0 and target_string_at_start==False: \n",
    "                new_df = pd.concat([new_df, original_df[col]], axis=1)\n",
    "            if col.find(string_) == 0 and target_string_at_start==True:\n",
    "                new_df = pd.concat([new_df, original_df[col]], axis=1)\n",
    "        \n",
    "    return new_df\n",
    "\n",
    "def return_stats_on_group(original_df, group_column, group_identifiers, data_group, data_columns_exact_match=False):\n",
    "\n",
    "    group_flag = []\n",
    "    group_flag = np.array(original_df[group_column] == group_identifiers[0])\n",
    "\n",
    "    for i in range(1, len(group_identifiers)):\n",
    "        group_flag_ = np.array(original_df[group_column] == i)\n",
    "        group_flag = group_flag or group_flag_\n",
    "    results_df = original_df[group_flag]\n",
    "    results_df = results_df.drop(group_column, axis=1) \n",
    "\n",
    "    #print(type(float(\"{:.2f}\".format(results_df.values.mean()))))\n",
    "\n",
    "    return float(\"{:.2f}\".format(results_df.values.mean())), float(\"{:.2f}\".format(results_df.values.std()))\n",
    "\n",
    "#create data tables\n",
    "df_results = pd.DataFrame()\n",
    "df_reduced = pd.DataFrame()\n",
    "df_reduced = transfer_columns(df_reduced, df, [\"isocntry\", \"qa1a_\"], target_string_at_start=True, data_columns_exact_match=False)    \n",
    "\n",
    "#return results\n",
    "data_group_name = \"qa1a\"\n",
    "unit_group_name = \"GB\"\n",
    "output_mean, output_std = return_stats_on_group(df_reduced, \"isocntry\", [\"GB\"], [\"qa1a_\"], data_columns_exact_match=False)\n",
    "\n",
    "#enter data to series\n",
    "result_dict = {(data_group_name, \"mean\"): output_mean, (data_group_name, \"std\"): output_std}\n",
    "result_series = pd.Series(result_dict, name=unit_group_name)\n",
    "df_results = df_results.append(result_series)\n",
    "\n",
    "df_results\n",
    "\n",
    "#I need to reform the data as a multi-index dictionary.\n",
    "#With the key being: Country, Value Name, Value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_columns = [\"qa1a_1\", \"qa1a_2\", \"qa1a_3\"]\n",
    "df_test = df.loc[df[\"isocntry\"] == \"GB\"]\n",
    "\n",
    "test = df_test[test_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is for experimenting with mutli-dimensional python dictionaries\n",
    "\n",
    "test_dic = {\n",
    "('A', 'a', \"mean\"): [1, 2, 3, 4, 5],\n",
    "('A', 'a', \"std\"): [1, 2, 3, 4, 5],\n",
    "('A', 'b', \"mean\"): [6, 7, 8, 9, 1],\n",
    "('A', 'b', \"std\"): [6, 7, 8, 9, 1],\n",
    "('B', 'a', \"mean\"): [2, 3, 4, 5, 6],\n",
    "('B', 'a', \"std\"): [2, 3, 4, 5, 6],\n",
    "('B', 'b', \"mean\"): [7, 8, 9, 1, 2],\n",
    "('B', 'b', \"std\"): [7, 8, 9, 1, 2] }\n",
    "\n",
    "\n",
    "\n",
    "test_dic_insert = {\n",
    "('a', \"mean\"): [1, 2, 3, 4, 5],\n",
    "('a', \"std\"): [1, 2, 3, 4, 5],\n",
    "('b', \"mean\"): [6, 7, 8, 9, 1],\n",
    "('b', \"std\"): [6, 7, 8, 9, 1],\n",
    "}\n",
    "\n",
    "\n",
    "#def update_key(dict):\n",
    "#    for entry in dict:\n",
    "\n",
    "dict_1 = {(\"group_1\", \"mean\"): 1, (\"group_1\", \"std\"): 2,\n",
    "          (\"group_2\", \"mean\"): 2, (\"group_2\", \"std\"): 0.5}\n",
    "test_series_1 = pd.Series(dict_1, name=\"GB\")\n",
    "\n",
    "dict_2 = {(\"group_1\", \"mean\"): 3, (\"group_1\", \"std\"): 3,\n",
    "          (\"group_2\", \"mean\"): 5, (\"group_2\", \"std\"): 8}\n",
    "test_series_2 = pd.Series(dict_2, name=\"IT\")\n",
    "\n",
    "pd.DataFrame([test_series_1, test_series_2])\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d686fb4bba1cd81d322bac49812b464465e293b78591a47e52bedfb124e592be"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
